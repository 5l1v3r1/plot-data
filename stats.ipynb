{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "hits = [\n",
    "# '2018-08-10_00-00-00', #0\n",
    "# '2018-08-29_11_32_44',\n",
    "'2018-08-29_22-54-16', #2\n",
    "'2018-09-05_21-38-43',\n",
    "'2018-09-07_11-34-48',\n",
    "'2018-09-08_09-41-18',\n",
    "'2018-09-09_10-28-14', #6\n",
    "'2018-09-10_10-36-44', #7\n",
    "'2018-09-11_11-09-18',\n",
    "#'2018-09-12_11-04-34',\n",
    "'2018-09-13_12-06-31',\n",
    "]\n",
    "# base = 'hits/' + hits[8]\n",
    "def cd(file):\n",
    "    return os.path.join(base, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_plot(assignments):\n",
    "    times = []\n",
    "    submit_times = []\n",
    "    for l in assignments:\n",
    "        submit = datetime.datetime.strptime(l['SubmitTime'][:-6], \"%Y-%m-%d %H:%M:%S\")\n",
    "        accept = datetime.datetime.strptime(l['AcceptTime'][:-6], \"%Y-%m-%d %H:%M:%S\")\n",
    "        submit_times.append(submit)\n",
    "        diff = (submit - accept).total_seconds()/60.0\n",
    "        times.append({\"diff\": diff})\n",
    "    spec = {\n",
    "      \"data\": {\"values\": times},\n",
    "      \"mark\": \"bar\",\n",
    "      \"encoding\": {\n",
    "        \"x\": {\n",
    "          \"field\": \"diff\",\n",
    "          \"type\": \"quantitative\",\n",
    "          \"bin\": {\"step\": 1} \n",
    "        },\n",
    "        \"y\": {\n",
    "          \"aggregate\": \"count\",\n",
    "          \"type\": \"quantitative\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    print('min - max: ', min(submit_times), max(submit_times))\n",
    "    print('mean duration: ', np.mean(list(map(lambda d: d['diff'], times))))\n",
    "    return alt.VegaLite(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener_assignments = json.load(open(cd('listener.assignments')))\n",
    "speaker_assignments = json.load(open(cd('speaker.assignments')))\n",
    "display(duration_plot(speaker_assignments))\n",
    "display(duration_plot(listener_assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "\n",
    "def by_worker(assign):\n",
    "    workers = collections.defaultdict(int)\n",
    "    for a in assign:\n",
    "        workers[a['WorkerId']] += 1\n",
    "    descending = sorted(workers.items(), key=lambda a: -a[1])\n",
    "    return collections.OrderedDict(descending) \n",
    "\n",
    "listener_counts = by_worker(listener_assignments)\n",
    "speaker_counts = by_worker(speaker_assignments)\n",
    "intersection = set(speaker_counts.keys()).intersection(listener_counts.keys())\n",
    "\n",
    "for k in intersection:\n",
    "    print(k, listener_counts[k], speaker_counts[k])\n",
    "print('speak: {} listener {} overlap {}'.format(len(speaker_counts), len(listener_counts), len(intersection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from scripts.query_line import QueryLine\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "def isfloat(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def reduce_formula(x):\n",
    "    if x.find(':') == -1:\n",
    "        print('COLON_NOT_FOUND', x)\n",
    "        return 'COLON_NOT_FOUND'\n",
    "    v = x[x.index(':')+1:]\n",
    "    return x[:x.index(':')] + ('number' if isfloat(v) else v)\n",
    "\n",
    "def to_html(spec):\n",
    "    options = {'rendered': 'svg', 'width': 800, 'height': 800}\n",
    "    return alt.utils.html.spec_to_html(spec, 'vega-lite', '3', '3', '2', embed_options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import process_listener as pl\n",
    "from scripts import guess_id as guess\n",
    "# adds annotations\n",
    "\n",
    "def aggregate_all():\n",
    "    examples = []\n",
    "    listener_log = []\n",
    "    for h in hits[0:1] + hits[2:]:\n",
    "        print('processing', h)\n",
    "        speaker_path = os.path.join('hits', h, 'speaker.jsonl')\n",
    "        listener_path = os.path.join('hits', h, 'listener.raw.jsonl')\n",
    "        lines = [QueryLine(line.strip()) for line in open(speaker_path, 'r').readlines()]\n",
    "        examples += [l for l in lines if l.is_example()]\n",
    "        listener_log += [QueryLine(line.strip()) for line in open(listener_path, 'r').readlines()]\n",
    "#     formulas = [l.example()['targetFormula'] for l in examples]\n",
    "#     paths = list(map(lambda x: reduce_formula(x), formulas))\n",
    "    paths = [reduce_formula(l.example()['targetFormula'])\n",
    "             + guess.hash_query(l.json, keys=['context']) for l in examples]\n",
    "    pathsset = set(paths)\n",
    "    pathcounter = collections.Counter(paths)\n",
    "    countisone = [k for k in pathcounter.keys() if pathcounter[k] == 1]\n",
    "    freqfreq = pathcounter.values()\n",
    "    spec = {\n",
    "      \"data\": {\"values\": [{\"freq_of_freq\": v} for v in freqfreq]},\n",
    "      \"mark\": \"bar\",\n",
    "      \"encoding\": {\n",
    "        \"x\": {\n",
    "          \"field\": \"freq_of_freq\",\n",
    "          \"type\": \"quantitative\",\n",
    "          \"bin\": {\"step\": 1} \n",
    "        },\n",
    "        \"y\": {\n",
    "          \"aggregate\": \"count\",\n",
    "          \"type\": \"quantitative\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    chart = alt.VegaLite(spec)\n",
    "    display(chart)\n",
    "    print(len(paths), len(pathsset), len(countisone))\n",
    "    \n",
    "    pl.process_listener(examples, listener_log)\n",
    "    speakers, listeners = pl.aggregate_turker(examples)\n",
    "    print('got {} examples, {} listeners log'.format(len(examples), len(listener_log)))\n",
    "    return speakers, listeners\n",
    "\n",
    "speakers, listeners = aggregate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(data, field):\n",
    "    records = [{field: i} for i in data]\n",
    "    spec = {\n",
    "      \"data\": {\"values\": records},\n",
    "      \"mark\": \"bar\",\n",
    "      \"encoding\": {\n",
    "        \"x\": {\n",
    "          \"field\": field,\n",
    "          \"type\": \"quantitative\",\n",
    "          \"bin\": {\"step\": 1} \n",
    "        },\n",
    "        \"y\": {\n",
    "          \"aggregate\": \"count\",\n",
    "          \"type\": \"quantitative\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    return alt.VegaLite(spec)\n",
    "\n",
    "def type2acc(stats):\n",
    "    total = stats['correct'] + stats['wrong'] + stats['skip'] \n",
    "    if total != 0:\n",
    "        correct = (stats['correct'])/(total)\n",
    "        wrong = (stats['wrong']) / (total)\n",
    "        skip = (stats['skip']) /(total)\n",
    "        return correct, wrong, skip\n",
    "    else:\n",
    "        return 0,0,0\n",
    "    \n",
    "    \n",
    "def print_stats():\n",
    "    overlaps = set(speakers.keys()).intersection(listeners.keys())\n",
    "    print(f's_count, l_count {len(speakers)} {len(listeners)}')\n",
    "    print(f'{len(overlaps)} in common')\n",
    "    speaker_utts = [len(s['utterances']) for k,s in speakers.items()]\n",
    "    display(hist(speaker_utts, 'utts per speaker'))\n",
    "    print(f'mean, median number of utterances {np.mean(speaker_utts):.3f} {np.median(speaker_utts)}')\n",
    "    all_utts = [u for k,s in speakers.items() for u in s['utterances']]\n",
    "    print('total {} utterances, mean_len {:.2f} chars, {:.2f} tokens'.format(\n",
    "        len(all_utts),\n",
    "        np.mean([len(u) for u in all_utts]),\n",
    "        np.mean([len(u.split(' ')) for u in all_utts])))\n",
    "    all_listeners = [u for k,s in speakers.items() for u in s['listeners']]\n",
    "    print(len(all_listeners))\n",
    "    types = pl.aggregate_type(all_listeners)\n",
    "    print('correct, wrong, skip: {:.3f}, {:.3f}, {:.3f}'.format(*type2acc(types)))\n",
    "    \n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2row(l: QueryLine):\n",
    "    return {'utterance': l.utterance(), 'workerId': l.worker_id(), 'targetFormula': l.example()['targetFormula']} \n",
    "\n",
    "def speaker2row(id, l: dict):\n",
    "    return {'WorkerId': id, 'stats': l['stats'],\n",
    "            'utts': ', '.join(l['utterances']), 'listeners': len(l['listeners'])}\n",
    "\n",
    "def joint2row(id, l: dict):\n",
    "    l['WorkerId'] = id\n",
    "    return l\n",
    "\n",
    "joint = collections.defaultdict(lambda: {'WorkerId':'', 'total': 0})\n",
    "\n",
    "def fill_joint(rows, prefix):\n",
    "    for wid, r in rows.items():\n",
    "#         print('row', r)\n",
    "        jr = joint[wid]\n",
    "        jr['WorkerId'] = wid\n",
    "        stats = r['stats']\n",
    "        total = stats['correct'] + stats['wrong'] + stats['skip'] \n",
    "        correct, wrong, skip = 0.2, 0.6, 0.2\n",
    "        if total != 0:\n",
    "            correct = (stats['correct']) /  (total)\n",
    "            wrong = (stats['wrong']) /  (total)\n",
    "            skip = (stats['skip']) /  (total)\n",
    "        jr[prefix + '_correct'] = correct \n",
    "        jr[prefix + '_wrong'] = wrong\n",
    "        jr[prefix + '_skip'] = skip\n",
    "        jr[prefix + '_total'] = total\n",
    "        jr['total'] += total\n",
    "        \n",
    "def fill_utts(speakers):\n",
    "    for wid, r in speakers.items():\n",
    "#         print('row', r)\n",
    "        jr = joint[wid]\n",
    "        jr['WorkerId'] = wid\n",
    "        utts = r['utterances']\n",
    "        lenutt = len(utts)\n",
    "        jr['num_utts'] = lenutt \n",
    "        jr['utts'] = utts if lenutt <= 10 else utts[0:2]\n",
    "        jr['avg_len'] = np.mean([len(l.split(' ')) for l in utts])\n",
    "        \n",
    "fill_joint(speakers, 's')\n",
    "fill_utts(speakers)\n",
    "fill_joint(listeners, 'l')\n",
    "\n",
    "\n",
    "records = [joint2row(k, v) for k,v in joint.items()]\n",
    "agg_table = pd.DataFrame.from_records(records) \n",
    "agg_table.sort_values(by=['s_correct', 's_total', 'l_correct'], inplace=True, ascending=False)\n",
    "# display(agg_table)\n",
    "spec_list = []\n",
    "spec_list += [{\n",
    "  \"data\": {\"values\": records},\n",
    "  \"description\": \"accuracies\",\n",
    "  \"mark\": \"circle\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\n",
    "      \"field\": \"s_correct\",\n",
    "      \"type\": \"quantitative\"        \n",
    "    },\n",
    "    \"y\": {\n",
    "      \"field\": \"l_correct\",\n",
    "      \"type\": \"quantitative\"        \n",
    "    },\n",
    "    \"size\": {\n",
    "        \"field\": \"num_utts\",\n",
    "        \"type\": \"quantitative\"\n",
    "    },\n",
    "    \"opacity\": {\"value\": 0.5},\n",
    "    \"tooltip\": {\n",
    "        \"field\": \"l_correct\",\n",
    "        \"type\": \"quantitative\"\n",
    "    }\n",
    "  }\n",
    "}]\n",
    "spec_list += [{\n",
    "  \"data\": {\"values\": records},\n",
    "  \"description\": \"correlation\",\n",
    "  \"mark\": \"circle\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\n",
    "      \"field\": \"s_correct\",\n",
    "      \"type\": \"quantitative\"        \n",
    "    },\n",
    "    \"y\": {\n",
    "      \"field\": \"l_total\",\n",
    "      \"type\": \"quantitative\"        \n",
    "    },\n",
    "    \"size\": {\n",
    "        \"field\": \"num_utts\",\n",
    "        \"type\": \"quantitative\"\n",
    "    },\n",
    "    \"opacity\": {\"value\": 0.5},\n",
    "    \"tooltip\": {\n",
    "        \"field\": \"utts\",\n",
    "        \"type\": \"nominal\"\n",
    "    }\n",
    "  }\n",
    "}]\n",
    "\n",
    "chart = alt.VegaLite(spec_list[0])\n",
    "display(chart)\n",
    "\n",
    "for spec in spec_list:\n",
    "    html = to_html(spec)\n",
    "    name = spec['description']\n",
    "    open(name + '.html', 'w').write(to_html(spec))\n",
    "\n",
    "corr = agg_table.corr()\n",
    "display(corr)\n",
    "display(agg_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_table = pd.DataFrame.from_records([speaker2row(k, v) for k,v in speakers.items()])\n",
    "ex_table.sort_values(by=['listeners'])\n",
    "display(ex_table)\n",
    "open('visualize.html', 'w').write(table.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
